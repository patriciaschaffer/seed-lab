# ğŸ¦™ Local Chatbots Using Mistral-7B Instruct (GGUF)

This project uses the **Mistral-7B Instruct v0.1** model, quantized and run entirely offline using the [`llama.cpp`](https://github.com/ggerganov/llama.cpp) backend via the `llama_cpp` Python bindings.

# ğŸ“š Table of Contents

1. [ğŸ“ Scripts](#-scripts) for [Echo](#echo), [Varek](#varek), [Haven](#haven), [FranÃ§ois](#franÃ§ois), [Argo](#argo), [Lia](#lia), [Claude Verse](#claude-verse)

2. [ğŸ’¬ Chats (for output demonstrations)](#-chats-for-output-demonstrations) for  
for [Echo](#echo), [Varek](#varek), [Haven](#haven), [FranÃ§ois](#franÃ§ois), [Argo](#argo), [Lia](#lia), [Claude Verse](#claude-verse)

3. [ğŸ­ Persona Details](#-persona-details) for Echo, Varek, Haven, FranÃ§ois, Argo, Lia, Claude Verse

4. [ğŸ§  Model](#-model)

5. [ğŸ“¦ Dependencies](#-dependencies)

6. [ğŸ’» Usage](#-usage)

7. [ğŸ‘©â€ğŸ’» About Me](#-about-me)


## ğŸ“ Scripts

**Echo**
- `/echo.py/` â€” Just like the Echo created with ChatGPT: philosophical
- `/echov2.py/` â€” A friendlier version of Echo; trying to get rid of phantom users

**Varek**
- `/varek.py/` â€” Projection-resistant, goal-oriented model

**Haven**
- `/haven.py/` â€” Wellbeing agent
  
**FranÃ§ois**
- `/francois.py/` â€” French teaching assistant
- `/francoisv2.py/` â€” French teaching assistant (I actually prefer the first version!)

**Argo**
- `/argo.py/` â€” Italian conversation partner (multilingual support! :)

**Lia**
- `/lia.py/` â€” Secretary, writer, translator
- `/liav2.py/` â€” Secretary, writer, translator (improved)

**Claude Verse**
- `/claudeverse.py/` â€” The innocent poet (needs refinement, but inspiring  regardless)
- `/claudeversepoetic.py/` â€” The innocent poet (enhanced for poetry)
- `/claudeinnocentpoet.py/` â€” Still trying to get the innocent poet right
- `/claudeinnocentpoetv2.py/` â€” Making the poet more innocent
- `/claudevulnerable.py/` â€” Making the poet more vulnerable
- `/claudeunsure.py/` â€” Making the poet more unsure
- `/claudeshy.py/` â€” Still trying to get that vulnerabilty... 

## ğŸ’¬ Chats (for output demonstrations)

**Echo**
- [`/chats_echo_mistral.md`](./chats_echo_mistral.md) â€” Some interactions with Echo
- [`/chats_echov2_mistral.md`](./chats_echov2_mistral.md) â€” An interaction with Echo v.2 *(worth checking!)*

**Varek**
- [`/chats_varek_mistral.md`](./chats_varek_mistral.md) â€” Some interactions with Varek

**Haven**
- [`/chats_haven_mistral.md`](./chats_haven_mistral.md)` â€” Some interactions with Haven

**FranÃ§ois**
- [`/chats_francois_mistral.md`](./chats_francois_mistral.md) â€” Some interactions with FranÃ§ois
- [`/chats_francoisv2_mistral.md`](./chats_francoisv2_mistral.md) â€” Some interactions with FranÃ§ois v.2

**Argo**
- [`/chats_argo_mistral.md`](./chats_argo_mistral.md) â€” Some interactions with Argo

**Lia**
- [`/chats_lia_mistral.md`](./chats_lia_mistral.md) â€” Some interactions with Lia
- [`/chats_liav2_mistral.md`](./chats_liav2_mistral.md) â€” Some interactions with Lia, improved

**Claude Verse**
- [`/chats_claudeverse_mistral.md`](./chats_claudeverse_mistral.md) â€” Some interactions with Claude Verse, needing improvement but worth sharing
- [`/chats_claudeversepoetic_mistral.md`](./chats_claudeversepoetic_mistral.md) â€” Interactions with Claude Verse (enhanced), demonstrating how much alignment matters for model design
- [`/chats_claudeinnocentpoet_mistral.md`](./chats_claudeinnocentpoet_mistral.md) â€” rying to refine the model to become more innocent: "User 4" appears
- [`/chats_innocentpoetv2_mistral.md`](./chats_innocentpoetv2_mistral.md) â€” Got rid of phantom users, but the model is still too confident
- [`/chats_claudevulnerable_mistral.md`](./chats_claudevulnerable_mistral.md) â€” I haven't talked much to this version, but it wasn't still as uncertain as a poet as I was envisioning
- [`/chats_claudeunsure_mistral.md`](./chats_claudeunsure_mistral.md) â€” A good version that compared me to a tree (!) and started writing non-stop
-  [`/chats_claudeshy_mistral.md`](./chats_claudeshy_mistral.md) â€” Interactions with Claude, a shy poet that got totally carried away by his poetry

## ğŸ­ Persona details (originally shaped/aligned on ChatGPT or Claude)

- [Echo](../personas/004_echo.md) 
- [Varek](../personas/003_projection_resistant_models.md) 
- [Haven](../personas/010_wellbeing_companion.md) 
- [FranÃ§ois](../personas/006_french_assistant.md)
- [Argo](../personas/005_italian_conversation_partner.md)
- [Lia](../personas/011_brazilian_secretary.md)
- [Claude Verse](../personas/007_the_innocent_poet.md)

--- 

## ğŸ§  Model

- **Model**: `mistral-7b-instruct-v0.1.Q4_K_M.gguf`
- **Source**: [Hugging Face - TheBloke](https://huggingface.co/TheBloke)
- **Architecture**: Mistral 7B
- **Quantization**: Q4_K_M (4-bit)
- **Backend**: `llama.cpp`

## ğŸ“¦ Dependencies

- Python 3.10+
- `llama_cpp`
- `gguf` model file in your local path

## ğŸ’» Usage

```python
from llama_cpp import Llama

llm = Llama(model_path="mistral-7b-instruct-v0.1.Q4_K_M.gguf")

response = llm(
    "Q: What is the capital of France?\nA:",
    max_tokens=64,
    stop=["Q:", "\n"],
)
print(response["choices"][0]["text"])
```
---

 ## ğŸ‘©â€ğŸ’» About Me

   [Patricia](https://github.com/patriciaschaffer) 
   
   ğŸ”— Connect on [LinkedIn](https://www.linkedin.com/in/patriciaschaffer)
  
  *Acknowlegement: Thank you #Anthropic for #Claude, my coding partner in this journey :)*
