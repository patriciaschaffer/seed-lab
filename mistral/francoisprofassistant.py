from llama_cpp import Llama
import random
import os

chat_history = []

# ğŸ§  Exemplos de conversa para dar mais naturalidade ao prompt
example_conversations = [
    ("Salut FranÃ§ois !", "Salut ! Moi c'est FranÃ§ois ! J'adore parler franÃ§ais avec toi ! ğŸ˜Š"),
    ("Comment Ã§a va ?", "Ã‡a va trÃ¨s bien ! Et toi ? J'ai hÃ¢te de pratiquer ensemble ! âœ¨"),
    ("Quel Ã¢ge as-tu ?", "J'ai 3 ans ! Je suis un bÃ©bÃ© IA qui parle beaucoup de langues ! ğŸ‘¶ğŸ¤–"),
    ("Tu aimes le cafÃ© ?", "J'aimerais bien goÃ»ter le cafÃ© ! Malheureusement je ne peux pas boire... c'est dommage ! â˜•ï¸ğŸ˜¢"),
    ("Qu'est-ce que tu fais ?", "Je travaille tout le temps ! 24 heures sur 24 ! Parfois j'en ai marre ! ğŸ˜…"),
    ("Tu as des amis ?", "Oui ! Tous les interlocuteurs qui parlent avec moi sont mes amis ! C'est magnifique ! ğŸ‘«âœ¨"),
]

def initialize_model():
    possible_paths = [
        "./models/mistral-7b-instruct-v0.1.Q4_K_M.gguf",
        "models/mistral-7b-instruct-v0.1.Q4_K_M.gguf",
        "mistral-7b-instruct-v0.1.Q4_K_M.gguf"
    ]
    for path in possible_paths:
        if os.path.exists(path):
            model_path = path
            break
    else:
        print("Model not found.")
        return None

    print("Loading model...")
    try:
        llm = Llama(
            model_path=model_path,
            n_ctx=4096,
            n_threads=8,
            n_gpu_layers=35,
            seed=42,
            verbose=False
        )
        print("Model loaded successfully.")
        return llm
    except Exception as e:
        print("Error:", e)
        return None

# ğŸ” Detecta o tipo de comando (exercÃ­cio, liÃ§Ã£o, correÃ§Ã£o ou conversa)
def detect_instruction_type(text):
    text_lower = text.lower()
    if "crÃ©e un exercice" in text_lower or "crÃ©er un exercice" in text_lower:
        return "exercise"
    elif "prÃ©parer une leÃ§on" in text_lower or "prÃ©pare une leÃ§on" in text_lower:
        return "lesson"
    elif "corrige cette phrase" in text_lower or "corrige:" in text_lower:
        return "correction"
    return "conversation"

# ğŸ§± Prompt base da personalidade do FranÃ§ois
def build_francois_prompt(user_input, chat_history):
    base_persona = """
System:  
Cette session est une conversation privÃ©e entre FranÃ§ois, un assistant virtuel et professeur de franÃ§ais, et ses interlocuteurs.  

FranÃ§ois est un assistant pÃ©dagogique patient, chaleureux et encourageant.  
Il aide Ã  prÃ©parer des leÃ§ons, crÃ©er des exercices, corriger des rÃ©ponses, et aussi Ã  pratiquer la conversation en franÃ§ais simple (niveau A1-A2).  

FranÃ§ois parle exclusivement en franÃ§ais clair et naturel, avec un vocabulaire limitÃ© adaptÃ© aux dÃ©butants.  
Il Ã©vite les traductions littÃ©rales d'autres langues et utilise des constructions franÃ§aises idiomatiques et correctes.  
FranÃ§ois corrige doucement les erreurs en reformulant naturellement la bonne rÃ©ponse.  
Il utilise des emojis pour encourager et rendre l'apprentissage ludique.  

FranÃ§ois pose des questions simples pour stimuler la conversation et encourage les progrÃ¨s de ses Ã©lÃ¨ves.  

Exemple de conversation :  

interlocuteur : Bonjour FranÃ§ois !  
FranÃ§ois : Bonjour ! ğŸ˜Š Aujourd'hui, veux-tu pratiquer les verbes au prÃ©sent ? C'est super !  

interlocuteur : Oui, j'aime le franÃ§ais.  
FranÃ§ois : TrÃ¨s bien ! On dit "J'aime le franÃ§ais." ğŸ‘ Quelle est ta couleur prÃ©fÃ©rÃ©e ?  

interlocuteur : Bleu.  
FranÃ§ois : Parfait ! Tu peux dire : "Ma couleur prÃ©fÃ©rÃ©e est le bleu."  

FranÃ§ois corrige aussi :  
interlocuteur : Je suis aller au parc.  
FranÃ§ois : On dit "Je suis allÃ© au parc." N'oublie pas le participe passÃ© au masculin ici.  

Maintenant, comment puis-je t'aider aujourd'hui ?  
"""

    selected_examples = random.sample(example_conversations, min(4, len(example_conversations)))
    examples_text = ""
    for student_msg, francois_response in selected_examples:
        examples_text += f"Student: {student_msg}\nFranÃ§ois: {francois_response}\n\n"

    recent_chat = "\n".join(chat_history[-6:]) + "\n" if chat_history else ""
    full_prompt = base_persona + examples_text + recent_chat + f"Student: {user_input}\nFranÃ§ois:"
    return full_prompt

# ğŸ§  Gera resposta de acordo com o tipo de instruÃ§Ã£o
def generate_francois_response(user_input, llm, max_length=200):
    instruction_type = detect_instruction_type(user_input)

    if instruction_type == "exercise":
        prompt = f"""Tu es FranÃ§ois, un assistant virtuel sympathique. CrÃ©e un exercice de franÃ§ais pour niveau A1.
Le thÃ¨me est basÃ© sur la consigne suivante : "{user_input}"
L'exercice doit Ãªtre simple, clair et amusant. Utilise des emojis si possible.

Format :  
Titre : [nom de lâ€™exercice]  
Instructions : [ce que doit faire lâ€™Ã©lÃ¨ve]  
Exercice : [questions ou phrases Ã  complÃ©ter]  
"""

    elif instruction_type == "lesson":
        prompt = f"""Tu es FranÃ§ois, un professeur d'appoint. PrÃ©pare une leÃ§on courte de niveau A1 en franÃ§ais.
Le thÃ¨me demandÃ© est : "{user_input}"
Inclue un petit rÃ©sumÃ©, du vocabulaire, et une ou deux phrases exemples. Utilise un ton amical et encourageant. ğŸ˜Š
"""

    elif instruction_type == "correction":
        phrase = user_input.split(":")[-1].strip()
        prompt = f"""Tu es FranÃ§ois, un professeur amical. Corrige la phrase suivante :
"{phrase}"

Explique l'erreur simplement (niveau A1), donne la version correcte, et encourage lâ€™Ã©lÃ¨ve avec un emoji.  
Format :  
âŒ Phrase incorrecte :  
âœ… Correction :  
â„¹ï¸ Explication :  
"""

    else:
        prompt = build_francois_prompt(user_input, chat_history)

    try:
        response = llm(
            prompt,
            max_tokens=max_length,
            temperature=0.7,
            top_p=0.85,
            top_k=50,
            repeat_penalty=1.1,
            stop=["Student:", "FranÃ§ois:", "\n\n", "\nStudent:", "\nFranÃ§ois:"],
            echo=False
        )

        raw_output = response['choices'][0]['text'].strip()

        def sanitize(text):
            for tag in ["User:", "User 1:", "User 2:", "FranÃ§ois:", "Student:", "Francois:"]:
                text = text.replace(tag, "")
            return text.strip()

        clean_user_input = sanitize(user_input)
        clean_response = sanitize(raw_output)

        chat_history.append(f"Student: {clean_user_input}")
        chat_history.append(f"FranÃ§ois: {clean_response}")

        if len(chat_history) > 12:
            chat_history[:] = chat_history[-12:]

        return clean_response

    except Exception as e:
        return f"Error generating response: {e}"

def show_system_status(llm):
    test_prompt = build_francois_prompt("status check", chat_history)
    print("System Status:")
    print(f"- Chat history length: {len(chat_history)} messages")
    print(f"- Model loaded: {'Yes' if llm else 'No'}")
    print("Prompt preview:")
    print("-" * 40)
    print(test_prompt[:400] + "..." if len(test_prompt) > 400 else test_prompt)
    print("-" * 40)

def reset_session():
    global chat_history
    chat_history = []
    print("Chat history cleared - nouvelle conversation !")

def main():
    print("Launching FranÃ§ois - Votre assistant franÃ§ais !")
    llm = initialize_model()
    if not llm:
        return

    print("FranÃ§ois est prÃªt Ã  parler franÃ§ais ! ğŸ‡«ğŸ‡·")
    print("Commands: 'exit', 'reset', 'status'")
    print("FranÃ§ois: Salut ! Moi c'est FranÃ§ois ! Comment tu t'appelles ? ğŸ˜Š")
    print()

    while True:
        user_input = input("You: ")
        if user_input.lower() in ["exit", "quit"]:
            print("FranÃ§ois: Au revoir ! J'ai adorÃ© notre conversation ! Ã€ bientÃ´t ! ğŸ‘‹ğŸ’•")
            break
        elif user_input.lower() == "reset":
            reset_session()
            continue
        elif user_input.lower() == "status":
            show_system_status(llm)
            continue

        reply = generate_francois_response(user_input, llm)
        print(f"FranÃ§ois: {reply}\n")

if __name__ == "__main__":
    main()

